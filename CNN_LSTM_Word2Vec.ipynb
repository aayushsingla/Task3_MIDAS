{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "manufactured-default",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import feature_extraction, model_selection, naive_bayes, pipeline, manifold, preprocessing, metrics\n",
    "import multiprocessing\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "import nltk\n",
    "print(cores)\n",
    "from time import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, preprocessing as kprocessing\n",
    "from tensorflow.keras import backend as K\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "brave-concept",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our training set contains 11090 examples\n",
      "our test set contains 4754 examples\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('/home/aayush/task3_midas/datasets/imbalanced_dataset_200.csv')\n",
    "train, test = model_selection.train_test_split(dataset, test_size=0.3)\n",
    "x_train = train[\"pre_processed_text\"].values\n",
    "x_test = test[\"pre_processed_text\"].values\n",
    "y_train = train[\"category\"].values\n",
    "y_test = test[\"category\"].values\n",
    "print(\"our training set contains %d examples\"%(len(x_train)))\n",
    "print(\"our test set contains %d examples\"%(len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "oriental-ballet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.01 mins\n",
      "11090\n"
     ]
    }
   ],
   "source": [
    "w2v_model = Word2Vec(vector_size = 300,window=8, min_count=1, sg=1,  workers=cores-1)\n",
    "word_sentences = list()\n",
    "for x in x_train:\n",
    "    word_sentences.append(x.split())\n",
    "t = time()\n",
    "w2v_model.build_vocab(word_sentences, progress_per=100)\n",
    "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))\n",
    "print(len(word_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "balanced-flooring",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 1.77 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "w2v_model.train(word_sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "isolated-aquarium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chestbio', 0.5711948275566101),\n",
       " ('greenmom', 0.5627349019050598),\n",
       " ('pyjamasetspecifications', 0.5609691143035889),\n",
       " ('chairorka', 0.5544642210006714),\n",
       " ('greymom', 0.5522589087486267),\n",
       " ('qp', 0.5348389148712158),\n",
       " ('comfortablebio', 0.5308143496513367),\n",
       " ('topattractive', 0.5308120250701904),\n",
       " ('durablebela', 0.5293307900428772),\n",
       " ('bagssuitcase', 0.5269551873207092)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=['kid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "greenhouse-liberal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "print(w2v_model.wv.key_to_index[\"car\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "virtual-trailer",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8087dce410b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## create sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlst_text2seq\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m## padding sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m X_train = kprocessing.sequence.pad_sequences(lst_text2seq, \n\u001b[1;32m      5\u001b[0m                     maxlen=2000, padding=\"post\", truncating=\"post\")\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "## create sequence\n",
    "lst_text2seq= tokenizer.texts_to_sequences(x_train)\n",
    "## padding sequence\n",
    "X_train = kprocessing.sequence.pad_sequences(lst_text2seq, \n",
    "                    maxlen=2000, padding=\"post\", truncating=\"post\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_text2seq= tokenizer.texts_to_sequences(x_test)\n",
    "## padding sequence\n",
    "X_test = kprocessing.sequence.pad_sequences(lst_text2seq, \n",
    "                    maxlen=2000, padding=\"post\", truncating=\"post\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-vermont",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## start the matrix (length of vocabulary x vector size) with all 0s\n",
    "embeddings = np.zeros((len(w2v_model.wv.key_to_index)+1, 300))\n",
    "for word,idx in w2v_model.wv.key_to_index.items():\n",
    "    ## update the row with vector\n",
    "    try:\n",
    "        embeddings[idx] =  w2v_model.wv.get_vector(word)\n",
    "    ## if word not in model then skip and the row stays all 0s\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-beauty",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embeddings.shape)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-sixth",
   "metadata": {},
   "outputs": [],
   "source": [
    "## input\n",
    "x_in = layers.Input(shape=(2000,))\n",
    "## embedding\n",
    "x = layers.Embedding(embeddings.shape[0],  \n",
    "                     embeddings.shape[1],\n",
    "                     weights=[embeddings],\n",
    "                     input_length=2000, trainable=False)(x_in)\n",
    "\n",
    "## 2 layers of bidirectional lstm\n",
    "x = layers.Bidirectional(layers.LSTM(units=15, dropout=0.2, \n",
    "                         return_sequences=True))(x)\n",
    "x = layers.Bidirectional(layers.LSTM(units=15, dropout=0.2))(x)\n",
    "## final dense layers\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "y_out = layers.Dense(3, activation='softmax')(x)\n",
    "## compile\n",
    "model = models.Model(x_in, y_out)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-electric",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
